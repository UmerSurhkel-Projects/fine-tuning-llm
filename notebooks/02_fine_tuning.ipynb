{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine-Tuning: TechGadgets Support Bot\n",
        "\n",
        "This notebook handles the fine-tuning process:\n",
        "1. Upload training and validation files to OpenAI\n",
        "2. Create a fine-tuning job with specified parameters\n",
        "3. Monitor the training progress\n",
        "4. Retrieve the fine-tuned model ID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup and Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ OpenAI client initialized\n",
            "Model: gpt-4o-mini-2024-07-18\n",
            "Suffix: techgadgets-support\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "from dotenv import load_dotenv\n",
        "import time\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Fine-tuning configuration\n",
        "FINE_TUNING_CONFIG = {\n",
        "    \"model\": \"gpt-4o-mini-2024-07-18\",\n",
        "    \"training_file\": None,  # Will be set after upload\n",
        "    \"validation_file\": None,  # Will be set after upload\n",
        "    \"hyperparameters\": {\n",
        "        \"n_epochs\": 1,\n",
        "        \"batch_size\": 1,\n",
        "        \"learning_rate_multiplier\": None  # Auto\n",
        "    },\n",
        "    \"suffix\": \"techgadgets-support\",\n",
        "    \"seed\": 42\n",
        "}\n",
        "\n",
        "print(\"‚úÖ OpenAI client initialized\")\n",
        "print(f\"Model: {FINE_TUNING_CONFIG['model']}\")\n",
        "print(f\"Suffix: {FINE_TUNING_CONFIG['suffix']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Upload Training and Validation Files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üí° Fine-tuning requires a paid OpenAI account\n",
        "\n",
        "Fine-tuning uses billable tokens. If you see **\"You exceeded your current quota\"**:\n",
        "\n",
        "1. **Check billing**: [OpenAI Billing](https://platform.openai.com/account/billing) ‚Äî add a payment method or top up credits.\n",
        "2. **Check usage**: [OpenAI Usage](https://platform.openai.com/usage) ‚Äî confirm your plan allows fine-tuning.\n",
        "3. **Pricing**: [Fine-tuning pricing](https://openai.com/api/pricing/) ‚Äî e.g. gpt-4o-mini fine-tuning is charged per token.\n",
        "\n",
        "Free tier / trial credits usually do **not** include fine-tuning; you need a paid plan with available balance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploading training file...\n",
            "‚úÖ Training file uploaded: file-HubMu4aeHoD528JmrpVo4S\n",
            "   File name: training_data.jsonl\n",
            "   File size: 483064 bytes\n",
            "\n",
            "Uploading validation file...\n",
            "‚úÖ Validation file uploaded: file-G7JGvB35BHgFqeuYeCZsWR\n",
            "   File name: validation_data.jsonl\n",
            "   File size: 119054 bytes\n"
          ]
        }
      ],
      "source": [
        "# Upload training file\n",
        "print(\"Uploading training file...\")\n",
        "with open(\"../data/training_data.jsonl\", \"rb\") as f:\n",
        "    training_file = client.files.create(\n",
        "        file=f,\n",
        "        purpose=\"fine-tune\"\n",
        "    )\n",
        "    FINE_TUNING_CONFIG[\"training_file\"] = training_file.id\n",
        "    print(f\"‚úÖ Training file uploaded: {training_file.id}\")\n",
        "    print(f\"   File name: {training_file.filename}\")\n",
        "    print(f\"   File size: {training_file.bytes} bytes\")\n",
        "\n",
        "# Wait a moment for file processing\n",
        "time.sleep(2)\n",
        "\n",
        "# Upload validation file\n",
        "print(\"\\nUploading validation file...\")\n",
        "with open(\"../data/validation_data.jsonl\", \"rb\") as f:\n",
        "    validation_file = client.files.create(\n",
        "        file=f,\n",
        "        purpose=\"fine-tune\"\n",
        "    )\n",
        "    FINE_TUNING_CONFIG[\"validation_file\"] = validation_file.id\n",
        "    print(f\"‚úÖ Validation file uploaded: {validation_file.id}\")\n",
        "    print(f\"   File name: {validation_file.filename}\")\n",
        "    print(f\"   File size: {validation_file.bytes} bytes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Fine-Tuning Job"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating fine-tuning job...\n",
            "Configuration:\n",
            "  Model: gpt-4o-mini-2024-07-18\n",
            "  Training file: file-HubMu4aeHoD528JmrpVo4S\n",
            "  Validation file: file-G7JGvB35BHgFqeuYeCZsWR\n",
            "  Epochs: 1\n",
            "  Batch size: 1\n",
            "  Seed: 42\n",
            "  Suffix: techgadgets-support\n",
            "\n",
            "‚úÖ Fine-tuning job created!\n",
            "   Job ID: ftjob-tN3nlkG54KiphGn72u6LVmWk\n",
            "   Status: validating_files\n",
            "   Created at: 1770713593\n",
            "\n",
            "üíæ Save this Job ID for monitoring: ftjob-tN3nlkG54KiphGn72u6LVmWk\n"
          ]
        }
      ],
      "source": [
        "# Create fine-tuning job\n",
        "print(\"Creating fine-tuning job...\")\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Model: {FINE_TUNING_CONFIG['model']}\")\n",
        "print(f\"  Training file: {FINE_TUNING_CONFIG['training_file']}\")\n",
        "print(f\"  Validation file: {FINE_TUNING_CONFIG['validation_file']}\")\n",
        "print(f\"  Epochs: {FINE_TUNING_CONFIG['hyperparameters']['n_epochs']}\")\n",
        "print(f\"  Batch size: {FINE_TUNING_CONFIG['hyperparameters']['batch_size']}\")\n",
        "print(f\"  Seed: {FINE_TUNING_CONFIG['seed']}\")\n",
        "print(f\"  Suffix: {FINE_TUNING_CONFIG['suffix']}\")\n",
        "\n",
        "try:\n",
        "    from openai import BadRequestError\n",
        "except ImportError:\n",
        "    BadRequestError = Exception\n",
        "\n",
        "try:\n",
        "    fine_tune_job = client.fine_tuning.jobs.create(\n",
        "        training_file=FINE_TUNING_CONFIG[\"training_file\"],\n",
        "        validation_file=FINE_TUNING_CONFIG[\"validation_file\"],\n",
        "        model=FINE_TUNING_CONFIG[\"model\"],\n",
        "        hyperparameters=FINE_TUNING_CONFIG[\"hyperparameters\"],\n",
        "        suffix=FINE_TUNING_CONFIG[\"suffix\"],\n",
        "        seed=FINE_TUNING_CONFIG[\"seed\"]\n",
        "    )\n",
        "except BadRequestError as e:\n",
        "    err_body = getattr(e, \"body\", None) or getattr(e, \"response\", None) or {}\n",
        "    if hasattr(err_body, \"json\"):\n",
        "        try:\n",
        "            err_body = err_body.json()\n",
        "        except Exception:\n",
        "            err_body = {}\n",
        "    elif isinstance(err_body, str):\n",
        "        import json\n",
        "        try:\n",
        "            err_body = json.loads(err_body) if err_body else {}\n",
        "        except Exception:\n",
        "            err_body = {}\n",
        "    err_info = err_body.get(\"error\", {}) if isinstance(err_body, dict) else {}\n",
        "    err_code = err_info.get(\"code\", \"\")\n",
        "    err_msg = err_info.get(\"message\", str(e))\n",
        "    err_str = str(e).lower()\n",
        "    if err_code == \"exceeded_quota\" or (\"quota\" in err_str and \"exceeded\" in err_str):\n",
        "        print(\"\\n‚ùå Quota exceeded (billing / plan limit)\")\n",
        "        print(\"   \", err_msg)\n",
        "        print(\"\\n   What to do:\")\n",
        "        print(\"   ‚Ä¢ Add a payment method: https://platform.openai.com/account/billing\")\n",
        "        print(\"   ‚Ä¢ Check usage: https://platform.openai.com/usage\")\n",
        "        print(\"   ‚Ä¢ Fine-tuning requires a paid account with available balance.\")\n",
        "        raise SystemExit(0) from e\n",
        "    raise\n",
        "\n",
        "print(f\"\\n‚úÖ Fine-tuning job created!\")\n",
        "print(f\"   Job ID: {fine_tune_job.id}\")\n",
        "print(f\"   Status: {fine_tune_job.status}\")\n",
        "print(f\"   Created at: {fine_tune_job.created_at}\")\n",
        "\n",
        "# Save job ID for later reference\n",
        "JOB_ID = fine_tune_job.id\n",
        "print(f\"\\nüíæ Save this Job ID for monitoring: {JOB_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Monitor Training Progress"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monitoring fine-tuning job progress...\n",
            "(This may take several minutes to hours depending on dataset size)\n",
            "\n",
            "[0s] Status: succeeded\n",
            "\n",
            "‚úÖ Fine-tuning completed successfully!\n",
            "   Fine-tuned model ID: ft:gpt-4o-mini-2024-07-18:personal:techgadgets-support:D7e2cpyK\n",
            "   Trained tokens: 99476\n",
            "   Training loss: N/A\n",
            "   Validation loss: N/A\n",
            "\n",
            "üíæ Save this Model ID for evaluation: ft:gpt-4o-mini-2024-07-18:personal:techgadgets-support:D7e2cpyK\n"
          ]
        }
      ],
      "source": [
        "# Monitor the fine-tuning job\n",
        "print(\"Monitoring fine-tuning job progress...\")\n",
        "print(\"(This may take several minutes to hours depending on dataset size)\\n\")\n",
        "\n",
        "max_wait_time = 3600  # Maximum wait time in seconds (1 hour)\n",
        "check_interval = 30   # Check every 30 seconds\n",
        "elapsed_time = 0\n",
        "\n",
        "while elapsed_time < max_wait_time:\n",
        "    job_status = client.fine_tuning.jobs.retrieve(JOB_ID)\n",
        "    \n",
        "    print(f\"[{elapsed_time}s] Status: {job_status.status}\")\n",
        "    \n",
        "    if job_status.status == \"succeeded\":\n",
        "        print(f\"\\n‚úÖ Fine-tuning completed successfully!\")\n",
        "        print(f\"   Fine-tuned model ID: {job_status.fine_tuned_model}\")\n",
        "        print(f\"   Trained tokens: {job_status.trained_tokens}\")\n",
        "        print(f\"   Training loss: {getattr(job_status, 'training_loss', 'N/A')}\")\n",
        "        print(f\"   Validation loss: {getattr(job_status, 'validation_loss', 'N/A')}\")\n",
        "        \n",
        "        FINE_TUNED_MODEL_ID = job_status.fine_tuned_model\n",
        "        print(f\"\\nüíæ Save this Model ID for evaluation: {FINE_TUNED_MODEL_ID}\")\n",
        "        break\n",
        "    \n",
        "    elif job_status.status == \"failed\":\n",
        "        print(f\"\\n‚ùå Fine-tuning failed!\")\n",
        "        if hasattr(job_status, 'error'):\n",
        "            print(f\"   Error: {job_status.error}\")\n",
        "        break\n",
        "    \n",
        "    elif job_status.status in [\"validating_files\", \"queued\", \"running\"]:\n",
        "        if hasattr(job_status, 'training_file'):\n",
        "            print(f\"   Training file: {job_status.training_file}\")\n",
        "        if hasattr(job_status, 'validation_file'):\n",
        "            print(f\"   Validation file: {job_status.validation_file}\")\n",
        "        if hasattr(job_status, 'trained_tokens'):\n",
        "            print(f\"   Trained tokens so far: {job_status.trained_tokens}\")\n",
        "    \n",
        "    time.sleep(check_interval)\n",
        "    elapsed_time += check_interval\n",
        "\n",
        "if elapsed_time >= max_wait_time:\n",
        "    print(f\"\\n‚è±Ô∏è  Maximum wait time reached. Job may still be running.\")\n",
        "    print(f\"   Check status manually with: client.fine_tuning.jobs.retrieve('{JOB_ID}')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Retrieve Final Model Information\n",
        "\n",
        "**Note**: If the job is still running, you can run this cell later to check the status and get the model ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Job Status:\n",
            "  Status: succeeded\n",
            "  Model: gpt-4o-mini-2024-07-18\n",
            "  Fine-tuned model: ft:gpt-4o-mini-2024-07-18:personal:techgadgets-support:D7e2cpyK\n",
            "  Created at: 1770713593\n",
            "  Finished at: 1770714585\n",
            "  Trained tokens: 99476\n",
            "\n",
            "‚úÖ Fine-tuned model ready: ft:gpt-4o-mini-2024-07-18:personal:techgadgets-support:D7e2cpyK\n"
          ]
        }
      ],
      "source": [
        "# Retrieve final job status\n",
        "try:\n",
        "    final_job = client.fine_tuning.jobs.retrieve(JOB_ID)\n",
        "    \n",
        "    print(\"Final Job Status:\")\n",
        "    print(f\"  Status: {final_job.status}\")\n",
        "    print(f\"  Model: {final_job.model}\")\n",
        "    print(f\"  Fine-tuned model: {final_job.fine_tuned_model if hasattr(final_job, 'fine_tuned_model') and final_job.fine_tuned_model else 'Not ready yet'}\")\n",
        "    print(f\"  Created at: {final_job.created_at}\")\n",
        "    print(f\"  Finished at: {getattr(final_job, 'finished_at', 'Still running')}\")\n",
        "    \n",
        "    if hasattr(final_job, 'trained_tokens'):\n",
        "        print(f\"  Trained tokens: {final_job.trained_tokens}\")\n",
        "    if hasattr(final_job, 'training_loss'):\n",
        "        print(f\"  Training loss: {final_job.training_loss}\")\n",
        "    if hasattr(final_job, 'validation_loss'):\n",
        "        print(f\"  Validation loss: {final_job.validation_loss}\")\n",
        "    \n",
        "    if final_job.status == \"succeeded\":\n",
        "        print(f\"\\n‚úÖ Fine-tuned model ready: {final_job.fine_tuned_model}\")\n",
        "        FINE_TUNED_MODEL_ID = final_job.fine_tuned_model\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving job status: {e}\")\n",
        "    print(f\"Make sure JOB_ID is set correctly: {JOB_ID if 'JOB_ID' in locals() else 'Not set'}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
